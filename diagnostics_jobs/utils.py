# diagnostics_jobs/utils.py

import os
import cv2
import json
import logging
import requests 
import re
from urllib.parse import urlparse
from django.conf import settings
from django.core.files.storage import default_storage
# A MediaPipe importok maradnak az analyze_video_with_mediapipe-hoz
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2

logger = logging.getLogger(__name__)
# üí° GCS URL minta. A ([^/]+) a bucket neve, az (.+) a f√°jl el√©r√©si √∫tja!
GCS_URL_PATTERN = r"https://storage\.googleapis\.com/[^/]+/(.+)"

# --- BIZTONS√ÅGOS F√ÅJL EL√âR√âS KONVERT√ÅL√ÅSA ---
def get_local_video_path(job_url: str) -> str:
    """
    Kinyeri a vide√≥ let√∂lt√©s√©hez sz√ºks√©ges lok√°lis el√©r√©si utat.
    """

    gcs_object_path = None
    full_download_url = job_url  # Alap√©rtelmez√©sben a Job URL-t haszn√°ljuk

    # 1Ô∏è‚É£ Lok√°lis fejleszt√©s: MEDIA_URL ‚Üí MEDIA_ROOT
    if job_url.startswith(settings.MEDIA_URL) and "storage.googleapis.com" not in settings.MEDIA_URL:
        relative_path = job_url[len(settings.MEDIA_URL):]
        local_path = os.path.join(settings.MEDIA_ROOT, relative_path)
        logger.info(f"üíæ F√°jl bet√∂lt√©se MEDIA_ROOT-b√≥l: {local_path}")
        return local_path

    # 2Ô∏è‚É£ GCS URL feldolgoz√°sa
    if "storage.googleapis.com" in job_url:
        match = re.search(GCS_URL_PATTERN, job_url)
        if match:
            gcs_object_path = match.group(1)
        else:
            logger.error(f"‚ùå Nem siker√ºlt kinyerni a GCS objektum √∫tvonal√°t: {job_url}")
            raise RuntimeError(f"Hib√°s GCS URL form√°tum: {job_url}")

        # ‚úÖ Biztons√°gos f√°jln√©v (nem tartalmazza az al√°√≠r√°si param√©tereket)
        parsed_url = urlparse(full_download_url)
        clean_name = os.path.basename(parsed_url.path)
        if not clean_name:
            clean_name = "temp_video.mp4"

        local_temp_path = os.path.join("/tmp", clean_name)

        try:
            logger.info(f"‚¨áÔ∏è Vide√≥ let√∂lt√©se GCS-r≈ël: {full_download_url}")
            response = requests.get(full_download_url, stream=True)
            response.raise_for_status()

            with open(local_temp_path, "wb") as local_file:
                for chunk in response.iter_content(chunk_size=8192):
                    local_file.write(chunk)

            logger.info(f"‚úÖ Vide√≥ let√∂ltve: {local_temp_path}")
            return local_temp_path

        except Exception as e:
            logger.critical(f"‚ùå Hiba a GCS vide√≥ let√∂lt√©sekor: {e}")
            raise RuntimeError(f"Nem siker√ºlt let√∂lteni a vide√≥t a feldolgoz√°shoz: {e}")

    # 3Ô∏è‚É£ Ha sem MEDIA_URL, sem GCS nem illik
    raise RuntimeError(f"√ârv√©nytelen vide√≥ URL form√°tum: {job_url}")

def get_local_image_path(image_url: str) -> str:
    """
    Let√∂lti vagy el≈ëk√©sz√≠ti a k√©pet (JPG/PNG) a feldolgoz√°shoz.
    Kezeli a GCS al√°√≠rt URL-eket is ‚Äî lev√°gja a param√©tereket, √≠gy nem lesz t√∫l hossz√∫ a f√°jln√©v.
    """
    import re
    import requests
    import os
    import uuid
    from urllib.parse import urlparse

    if not image_url:
        raise ValueError("‚ùå Nincs megadva k√©p URL.")

    gcs_object_path = None
    full_download_url = image_url

    # 1Ô∏è‚É£ Lok√°lis fejleszt√©si k√∂rnyezet (MEDIA_URL)
    if image_url.startswith(settings.MEDIA_URL) and not "storage.googleapis.com" in settings.MEDIA_URL:
        relative_path = image_url[len(settings.MEDIA_URL):]
        local_path = os.path.join(settings.MEDIA_ROOT, relative_path)
        logger.info(f"üñºÔ∏è Lok√°lis k√©p bet√∂ltve: {local_path}")
        return local_path

    # 2Ô∏è‚É£ GCS form√°tum√∫ URL kezel√©se
    if "storage.googleapis.com" in image_url:
        parsed = urlparse(image_url)
        clean_path = parsed.path  # csak a path, query n√©lk√ºl
        clean_name = os.path.basename(clean_path)

        # ha valami√©rt √ºres lenne
        if not clean_name:
            clean_name = f"temp_{uuid.uuid4().hex}.jpg"

        # egyedi azonos√≠t√≥, hogy ne √ºtk√∂zz√∂n t√∂bb p√°rhuzamos feldolgoz√°s
        unique_suffix = uuid.uuid4().hex[:6]
        safe_filename = f"{os.path.splitext(clean_name)[0]}_{unique_suffix}{os.path.splitext(clean_name)[1]}"

        local_temp_path = os.path.join("/tmp", safe_filename)

        try:
            logger.info(f"‚¨áÔ∏è K√©p let√∂lt√©se GCS-r≈ël: {full_download_url}")
            response = requests.get(full_download_url, stream=True)
            response.raise_for_status()

            with open(local_temp_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            logger.info(f"‚úÖ K√©p let√∂ltve: {local_temp_path}")
            return local_temp_path

        except requests.exceptions.HTTPError as e:
            # fallback GCS API kliens
            logger.warning(f"‚ö†Ô∏è HTTP hiba a let√∂lt√©skor ({e}). Fallback GCS API kliensre.")
            try:
                from google.cloud import storage
                client = storage.Client()
                bucket_name = settings.GS_BUCKET_NAME
                bucket = client.bucket(bucket_name)
                blob_name = clean_path.lstrip('/')
                blob = bucket.blob(blob_name)
                blob.download_to_filename(local_temp_path)

                logger.info(f"‚úÖ GCS API-val let√∂ltve: {local_temp_path}")
                return local_temp_path

            except Exception as e2:
                logger.critical(f"‚ùå GCS API let√∂lt√©si hiba: {e2}")
                raise RuntimeError(f"Nem siker√ºlt let√∂lteni a k√©pet GCS API-n kereszt√ºl: {e2}") from e

        except Exception as e:
            logger.critical(f"‚ùå Kritikus hiba a k√©p let√∂lt√©sekor: {e}")
            raise RuntimeError(f"Nem siker√ºlt let√∂lteni a k√©pet: {e}")

    # 3Ô∏è‚É£ Ha sem a MEDIA_URL, sem a GCS URL nem illik r√°
    raise RuntimeError(f"√ârv√©nytelen k√©p URL form√°tum: {image_url}")


# ----------------------------------------------------------------------------------
# A analyze_video_with_mediapipe f√ºggv√©ny v√°ltozatlanul j√≥, a k√≥dfejleszt√©shez
# sz√ºks√©ges l√©p√©seket √©s a MediaPipe logik√°t tartalmazza.
# ----------------------------------------------------------------------------------

# --- VIDE√ì FELDOLGOZ√ì F√úGGV√âNY ---
def analyze_video_with_mediapipe(video_path: str, output_dir: str) -> dict:
    """
    MediaPipe Pose Estimator futtat√°sa a vide√≥n.
    Kinyeri a kulcspontokat, menti a JSON-t √©s visszaad egy egyszer≈±s√≠tett eredm√©nyt.
    """
    
    # Ellen≈ërz√©s
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Vide√≥ nem tal√°lhat√≥ a helyi el√©r√©si √∫ton: {video_path}")
    
    os.makedirs(output_dir, exist_ok=True)
    
    BaseOptions = python.BaseOptions
    PoseLandmarker = vision.PoseLandmarker
    PoseLandmarkerOptions = vision.PoseLandmarkerOptions
    VisionRunningMode = vision.RunningMode
    
    # üìù Konfigur√°ci√≥: 
    # V√°ltoztasd meg a "pose_landmarker.task" el√©r√©si √∫tvonal√°t, 
    # hogy megfeleljen a Docker image-ben l√©v≈ë el√©r√©si √∫tnak!
    MODEL_PATH = os.environ.get("MEDIAPIPE_MODEL_PATH", "/app/models/pose_landmarker.task")
    
    # Inicializ√°l√°s
    options = PoseLandmarkerOptions(
        base_options=BaseOptions(model_asset_path=MODEL_PATH),
        running_mode=VisionRunningMode.VIDEO,
        output_segmentation_masks=False,
    )

    # üé• Vide√≥ feldolgoz√°s
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError(f"Nem siker√ºlt megnyitni a vide√≥t: {video_path}")
        
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    all_keypoints = []

    with PoseLandmarker.create_from_options(options) as landmarker:
        frame_number = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # K√©p konvert√°l√°sa MediaPipe form√°tumba
            mp_image = (
                solutions.base_options.Image(image_format=solutions.base_options.ImageFormat.SRGB, data=frame)
            )

            # Elemz√©s
            # A frame id≈ëb√©lyeg√©t (ms) adjuk meg
            timestamp_ms = int(frame_number * 1000 / fps)
            result = landmarker.detect_for_video(mp_image, timestamp_ms)
            
            # Kulcspontok ment√©se
            if result.pose_landmarks:
                # Egyszer≈±s√≠tett JSON form√°tum a DiagnosticJob.result mez≈ëh√∂z
                keypoints = []
                for landmark in result.pose_landmarks[0]:
                    keypoints.append({
                        'x': landmark.x, 
                        'y': landmark.y, 
                        'z': landmark.z, 
                        'v': landmark.visibility
                    })
                all_keypoints.append({
                    'frame': frame_number,
                    'time_ms': timestamp_ms,
                    'keypoints': keypoints
                })
            
            frame_number += 1
        
        cap.release()

    # üíæ Eredm√©ny JSON f√°jl ment√©se
    json_path = os.path.join(output_dir, "analysis_raw_keypoints.json")
    with open(json_path, 'w') as f:
        json.dump(all_keypoints, f, indent=4)

    # üìä Egyszer≈±s√≠tett, mock eredm√©ny visszaad√°sa
    # Ezt fogjuk a job.result mez≈ëbe menteni, √©s ez ker√ºl majd a PDF-be
    # K√©s≈ëbb a MediaPipe keypoints alapj√°n sz√°molhatsz itt metrik√°kat
    return {
        "status": "success",
        "frames_analyzed": frame_number,
        "raw_json_file": json_path.replace(settings.MEDIA_ROOT, settings.MEDIA_URL), # URL-t adunk vissza
        "overall_rating": "J√≥",
        "shoulder_angle": 15.2, # Mock √©rt√©k
        "hip_symmetry": 98.5, # Mock √©rt√©k
    }